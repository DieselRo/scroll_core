LLMÂ AgentÂ CheatÂ SheetÂ âœï¸

Â StepÂ #

Â WhatÂ youÂ needÂ toÂ decideÂ /Â build

Â KeyÂ tipsÂ &Â gotchas

Â 1

Pick the workflow

Favour processes that are ambiguous, multiâ€‘step, rely on unstructured data, or where existing rule engines are brittle.

Â 2

Choose the model(s)

Start with the most capable model (e.g. o3â€‘mini / GPTâ€‘4o) to establish an accuracy baseline, then swap in cheaper models where quality remains â‰¥Â target.

Â 3

Craft system instructions

One paragraph for role + numbered rules. Derive from existing SOPs; be explicit about required outputs & any edgeâ€‘case branches.

Â 4

Define tools

Break into Data, Action and Orchestration tools. 1Â functionÂ =Â 1Â clear verb.  Include JSON schema & crisp description.

Â 5

Guardrails & policy

Layer: relevanceÂ â†’ safetyÂ â†’ moderationÂ â†’ output validation. Mark highâ€‘risk tools to require human approval.

Â 6

Choose orchestration pattern

Singleâ€‘agent loopManager (agentsâ€‘asâ€‘tools)Decentralised handâ€‘offs Start simple & split when prompts/tools become unwieldy.

Â 7

Memory / Session storage

Lightweight: inâ€‘memory or DB table keyed by app/user/session.  Advanced: RAG store or vector DB.

Â 8

Runâ€‘loop implementation

Whileâ€‘loop until: tool_call | final_output | error | max_turns.  Persist every Event to the Session log.

Â 9

Humanâ€‘inâ€‘theâ€‘loop

Escalate on exceeded retries or when highâ€‘risk action requested.  Provide session context to the human.

Â 10

Instrumentation & evals

Track turnâ€‘count, toolâ€‘use, latency, success metric.  Add lightweight eval harness for new regressions.

How to wire the pieces together ğŸ› ï¸

1.  Project skeleton

agents/              # python packages that define each agent class
  â””â”€ my_agent/
       â”œâ”€ __init__.py
       â”œâ”€ agent.py    # LlmAgent + tools registration
       â””â”€ requirements.txt
runners.py            # provided by ADK â€“ manages sessions & invocation

2.  Register the tools

from google.genai import types
from adk.tools import FunctionTool

@get_weather = FunctionTool(
    name="get_weather",
    description="Return current conditions for a city",
    parameters={"city": {"type": "string"}}
)

3.  Build the agent

from adk.agents.llm_agent import LlmAgent
from adk.planners.built_in_planner import BuiltInPlanner
from adk.code_executors.unsafe_local_code_executor import UnsafeLocalCodeExecutor

weather_agent = LlmAgent(
    name="WeatherAgent",
    model="o3-mini",
    description="Answers weather questions",
    canonical_tools=[get_weather],
    planner=BuiltInPlanner(thinking_config={"max_thoughts":3}),
    code_executor=UnsafeLocalCodeExecutor(),
)

4.  Add guardrails

from adk.guardrails import RegexGuardrail, ModerationGuardrail

weather_agent.input_guardrails = [
    RegexGuardrail(patterns=[r"(?i)drop\s+table", r"SELECT .* FROM"], action="block"),
    ModerationGuardrail(),
]

5.  Create the runâ€‘loop

from adk.runners import Runner

runner = Runner(
    app_name="weather_app",
    agent=weather_agent,
    session_service=InMemorySessionService(),
)

async for event in runner.run_async(user_id="u123", session_id="s1",
        new_message=types.Content(role="user", parts=[types.Part(text="Will it rain in Paris?")])):
    print(event.author, ":", event.content.parts[0].text)

6.  Escalation example

if event.actions.escalate:
    handoff_to_human(event, session)

7.  Observability hooks

Use RunConfig(streaming_mode=StreamingMode.TURN) and OpenTelemetry tracing built into ADK to measure latency, token usage & errors.

Drop this document into your repoâ€™s /docs folder â€“ it serves as a quick onâ€‘boarding reference for any engineer touching the agent stack.